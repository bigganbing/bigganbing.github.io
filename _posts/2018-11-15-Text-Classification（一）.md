---
layout:     post
title:      Text Classification（一）
subtitle:   文本分类一
date:       2018-11-15
author:     biggan
header-img: img/post-bg-swift.jpg
catalog: true
tags:
    - Text Classification
typora-root-url: ..
---

## 文本分类一

### 1.文本分类概述

#### （1）问题类型

- 二分类：二选一
- 多分类：多选一
- 多标签：多选不定项（相当于很多个二分类问题）

#### （2）问题解析

&emsp;文本分类问题主要分为**文本表示**和**分类**两部分。

- 文本表示：对文本进行特征提取，一个文本表示成一个向量。
- 分类：对提取的文本向量进行分类

**note**：

&emsp;一个文本中，通常由多个句子组成。大部分文本表示的做法是不考虑句子之间的关系，而都会把它当成一个句子处理。当然最好是考虑句子之间的关系。

&emsp;机器学习的方法，文本表示和分类这两个部分一般是独立的，而深度学习的方法，表示和分类是一体的，也就是我们俗称的端到端方式。

#### （3）文本预处理

&emsp;文本表示之前一般会对文本进行预处理，而对中英文的数据处理方式也有所不同。

- 中文

  主要包括文本分词和去停用词两部分。

  ①也可以不分词，基于字分析。分词可以使用$jieba$分词工具。

  ②去停用词可以维护一个停用词表。去掉像“然而”、 标点符号等只能反映句子语法结构的词语，而不能反映文献的主题的词汇。

- 英文

  ①分词，还原缩写，去停用词，词形还原，提取词干

  &emsp;推荐NLTK工具包进行处理，这些操作不一定需要全做。

  ②预训练词向量

  &emsp;深度学习方法中可以使用word2vec、glove等工具预训练词向量，也可以使用开源的训练好的词向量。

### 2.传统文本分类方法

#### （1）基本方法

&emsp;采用tf-idf等方法进行文本特征提取，然后喂给svm，knn, Random Forest等各种分类模型进行训练。

**note**：tfidf只是比较常用的一种方法，还有很多提取特征的方式。tfidf的方法一般都不差。

#### （2）tf-idf（词频-逆文档频率）

- **Tf**

  称为词频(term frequency)，即，某个词在文档中的出现频率。用于计算该词描述文档内容的能力。
  $$
  Tf=\frac{某个词在文本中出现的次数}{文本的单词总数}
  $$

- **Idf**

  称为逆文档频率(inverse document frequency, IDF)，用于计算该词区分文档的能力。
  $$
  Idf=log(\frac{文本总数}{包含该单词的文本的数量+1})
  $$
  其中，分母是为了避免分母为1。

- **Tf-Idf**
  $$
  Tf-Idf=Tf*Idf
  $$
  **Note**：TF-IDF与一个词在文档中的出现次数成正比，与该词在整个语料中的出现次数成反比。某个词的TF-IDF值就越大,对文章的重要性越高。某个词的TF-IDF值就越大,对文章的重要性越高。

通过此方法，就能计算一个文本中每一个单词的tf-idf值，然后将文本表示成一个词汇表长度的向量，此向量的每一个位置对应一个单词，若该位置对应单词在文本中出现，则其值为单词的tf-idf，若未出现则为0。

#### （3）利用sklearn工具包提取文本tf-idf特征。

- （2）中tf-idf特征提取是基于文档中的单词，往往文本中短语，即n_gram信息对文本分类也有很大的帮助，进行tfidf特征提取时，也可以以文本中的n_gram为元素。此时，$文本向量的长度=词汇总数+n\_gram$总数。

- $sklearn$中tf-idf特征提取函数$TfidfVectorizer$

  $tf
  = TfidfVectorizer(ngram\_range=(1, 2), analyzer=char')$

  通过$ngram\_range$参数可以指定$n\_gram$长度，(1,2)表示提取单词和二元组的$tfidf$特征。

#### （4）分类

&emsp;文本通过特征提取，表示成向量后，就可以通过$sklearn$各种掉包，尝试各种的分类器。一般使用SVM效果就会挺好。主要就是各种调参。

#### （5）补充

&emsp;对于大语料，还可以使用hash trick进行特征提取。

$Hs = HashingVectorizer(ngram_range=(1, 1), n\_features = 1024)$

仅基于词频，不考虑权重。相当于是对tf特征进行降维度。可以考虑将hash特征以及tf-idf特征串接起来，一起作为文本的特征。






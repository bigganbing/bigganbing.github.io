---
layout:     post
title:      Seminar:神经机器翻译漏译改进方法
subtitle:   Debut on 10.24.2018
date:       2018-10-24
author:     viewsetting
header-img: img/post-adjani.jpg
catalog: true
tags:
    - Idea Share
    - NLP
    - Neural Network
    - Seminar
---

## 简述

NMT解码的时候，使用$BeamSearch$算法，每次在给定的$BeamSize$中选出概率最大的$size$个单词，然后和之前选出的单词进行$size*size$的组合，再选出$size$个最优解。

由于概率计算的方式，导致最优解会偏向长度偏小的情况。（累乘，类似$Gradient\space Vanishing$)

$log P(y \vert x) = \sum_{j=1}^{\vert y\vert}log\space p( y_j\vert y<j , x)$ 

#### 长度正则化

$log P(y \vert x) /L^\alpha= \sum_{j=1}^{\vert y\vert}log\space p( y_j\vert y<j,x)/L^\alpha$

#### 覆盖率问题

引入attention机制，对目标数据加权。

#### 新方法： The Coverage Score（覆盖率）



引入超参数$\beta$，防止产生负无穷大值影响解码过程。

CS:

$c(x,y) = \sum_{t}^{\vert x\vert}log \max(\sum_{j}^{\vert y \vert} a_{i,j},\beta)$

然后线性插值:

$s(x,y)=(1-\alpha)\cdot  logP(y\vert x) + \alpha \cdot c(x,y)$







